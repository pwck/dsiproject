{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting COE premiums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem statement\n",
    "\n",
    "With more retailers and shoppers moving online, there is an increased demand for delivery services. <br>\n",
    "More corporations are looking to expand their private hire and delivery fleet. This is a pilot project to <br>\n",
    "investigate prediction of the COE premium for budgetary purposes. With a good prediction, stakeholders <br> \n",
    "would be able to better plan and allocate budgets. \n",
    "\n",
    "Would classic time series or regression models be able to achieve this with a RMSE of 5K or less?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Executive Summary\n",
    "\n",
    "All vehicles in Singapore require a COE. To register a vehicle, you must first place a bid for a Certificate of Entitlement (COE) in the corresponding vehicle category. A successful COE bid gives you the right to own a vehicle that can be used on the road for 10 years.\n",
    "COEs are released through open bidding exercises. At the end of the 10-year COE period, you can choose toÂ deregister your vehicle, or renew your COE.\n",
    "\n",
    "![COE](../images/COEcat.png)\n",
    "\n",
    "\n",
    "We began this project with 46 files and that quickly got reduced to 6 files which eventually left us with less than 10 features. \n",
    "Some challenges on working with real world data on top of the usual data cleaning are:\n",
    "- Finding data that are available within the same time frame, for example time frame of interest is between 2010 to 2020, datasets available may be from 2018 to 2020, or 2000 to 2012.\n",
    "- Finding data that are in the same granularity, for example when most datasets are in monthly, how to fit daily or weekly data together \n",
    "- Finding data that are categorized/grouped/labeled for your problem, for example COE categories vs CC vs Make vs passenger capacity. \n",
    "\n",
    "With limited features available, the first model we tried was Classic Time Series model ARIMA. Although the target, premium was not stationary we have taken premium's diff order 1 for ARIMA and GridSearched resulting with an order of (1,0,2). However ARIMA did not yield a very good predict.\n",
    "\n",
    "Since the time series models are out, next step was to look into feature engineering to increase the number of features for the other models that we are going to try. In feature engineering, there are two main groups that we created are shifted and EWMA features.\n",
    "- Shifted features, these are the features where values in the past have an impact to our target. Features that are shifted were ['cpi', 'fuel_price', 'dereg', 'premium'], and these are shifted by [1, 2, 3, 5, 10, 15, 20, 24, 48]. \n",
    "- EWMA Features, exponentially weighted moving average is a moving average where higher weights are given to the values that are nearer. Features that are EWMA are ['quota', 'bids_success', 'bids_received'] and they are applied on EWMA 3.\n",
    "\n",
    "Now that we have more features, ~45 features. We will use linear regression to analyze the features that has impact on the target. From the initial linear regression we were hitting RMSE of ~12K, after regularization and iterations of tuning. We were able to achieve RMSE for ~8K. \n",
    "\n",
    "Below is the top 3 features for each category from our Linear regression:\n",
    "![model metrics](../images/top_features.jpg)\n",
    "The top 3 features, premium_s1, quota_ema3 and bids_success_ema3 are consistent for both Category A and B. For Category C, quota_ema3 and bids_success_ema3 are on the 4th and 5th position which has significant impact on the target as well.\n",
    "\n",
    "Next we moved on to XGBoost Regressor to see if we can improve the RMSE further. While tuning the XGBoost Regressor we realised that using a single model and a single set was not helping. Hence we created models for each category along with it's own set of features. After many iterations of hyperparameters tuning and features selection for each model, we were able to achieve RMSE ~5K. \n",
    "<br>\n",
    "The final model metrics are as shown below:\n",
    "![model metrics](../images/metrics.jpg)\n",
    "\n",
    "prefix **lr** are Linear Regression model, the last character indicates the COE category<br>\n",
    "prefix **xgb** are XGBoost Regressor model, the last character indicates the COE category\n",
    "\n",
    "Although we have achieved a RMSE of < 5K, these models are far from perfect.\n",
    "In this project we have only scratch the surface of putting together a model to predict the COE premium.\n",
    "There are many more factors that affects COE prices. As with all corporate projects it is always a balance of Scope, Time and Cost. Projects have to be scoped in a way that it meets the business requirements, delivered on time and within cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Contents\n",
    "\n",
    "- [Data Processing](#Data-Processing)\n",
    "- [Data consolidation and features creation](#Data-consolidation-and-features-creation)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Modelling](#Modelling)\n",
    "- [Conclusions](#Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Importing python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.379648Z",
     "start_time": "2020-10-14T09:14:22.278397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EDA' from 'capstone' (C:\\pwck\\jupyter\\Project1234\\capstone\\code\\capstone\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c5eabf8195fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Importing custom classes/libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcapstone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGatherData\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDownloadFiles\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcapstone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUtils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUtils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcapstone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeployModel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pwck\\jupyter\\Project1234\\capstone\\code\\capstone\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGetData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'EDA' from 'capstone' (C:\\pwck\\jupyter\\Project1234\\capstone\\code\\capstone\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Importing standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import datetime as dt\n",
    "from dateutil.rrule import rrule, MONTHLY\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "# Importing custom classes/libraries\n",
    "from capstone.GatherData import DownloadFiles as gd\n",
    "from capstone.Utils import Utils as util\n",
    "from capstone.Model import DeployModel as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.421505Z",
     "start_time": "2020-10-14T09:14:22.280Z"
    }
   },
   "outputs": [],
   "source": [
    "#suppress UserWarning and SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.422503Z",
     "start_time": "2020-10-14T09:14:22.282Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting options for both pandas and numpy to show decimals up to 4 places\n",
    "pd.set_option('display.precision',4)\n",
    "np.set_printoptions(precision=4)\n",
    "%precision 4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.423501Z",
     "start_time": "2020-10-14T09:14:22.284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining a dictionary to hold the filenames.\n",
    "data_files = {\n",
    "    'cpi' : '../data/cpi_sgp.csv',                  # file containing cpi data\n",
    "    'fuel' : '../data/fuel_price.csv',              # file containing fuel prices\n",
    "    'manifest' : '../data/file_manifest_pipe.csv',  # manifest of all the files downloaded from LTA\n",
    "    'feat_map' : '../data/features.txt',            # feature mapping file for xgb analysis\n",
    "    'log_file' : '../log/capstone.log',             # log file for project\n",
    "    'pickle'   : '../data/finalized_model.pkl'              # pickle file for deployment\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a logger for all print outs, this logger will be helpful when moving the codes into deployment. <br> \n",
    "Especially when troubleshooting of codes in production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.424497Z",
     "start_time": "2020-10-14T09:14:22.287Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logger = logging.getLogger()\n",
    "logger.handlers[:] = []\n",
    "# set stdout logger\n",
    "lh = logging.StreamHandler(sys.stdout)\n",
    "lh.setFormatter(util.get_formatter())\n",
    "logger.addHandler(lh)\n",
    "# set file logger\n",
    "fh = logging.FileHandler(data_files['log_file'])\n",
    "fh.setFormatter(util.get_formatter(False))\n",
    "logger.addHandler(fh)\n",
    "# set logging level to DEBUG\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have created a DownloadFiles class for reading a manifest file and downloading the files from LTA.<br> Codes have been moved into class objects for ease of deployment as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.424497Z",
     "start_time": "2020-10-14T09:14:22.290Z"
    }
   },
   "outputs": [],
   "source": [
    "# instance of DownloadFiles class\n",
    "dl = gd.DownloadFiles()\n",
    "# reading in the list of files to be downloaded\n",
    "dl.get_manifest(data_files['manifest'], delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.425495Z",
     "start_time": "2020-10-14T09:14:22.292Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dataframe holding the manifest of files \n",
    "dl.manifest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.426493Z",
     "start_time": "2020-10-14T09:14:22.294Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl.view_df_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.427490Z",
     "start_time": "2020-10-14T09:14:22.296Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl.get_file_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.427490Z",
     "start_time": "2020-10-14T09:14:22.298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flag to indicate if files should be fetch from LTA (~45mins to 60mins)\n",
    "FETCH_FILES = False\n",
    "\n",
    "# if files are to be retrieved from LTA\n",
    "if FETCH_FILES:\n",
    "    dl.download_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.428486Z",
     "start_time": "2020-10-14T09:14:22.300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check downloaded file count\n",
    "dl.get_download_count()\n",
    "\n",
    "# check if any of the files are missing\n",
    "dl.check_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.429485Z",
     "start_time": "2020-10-14T09:14:22.302Z"
    }
   },
   "outputs": [],
   "source": [
    "# variables cleanup after downloading files\n",
    "del fh, lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Loading all files into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.429485Z",
     "start_time": "2020-10-14T09:14:22.306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to map frequency to date column name in files\n",
    "freq_dict = {\n",
    "    'annual': 'year',\n",
    "    'month': 'month',\n",
    "    'quarter': 'period'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.430481Z",
     "start_time": "2020-10-14T09:14:22.309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to hold all DataFrame\n",
    "alldata = dict()\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "# loop to load all csv into DataFrame\n",
    "for i, row in dl.manifest_df.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    col = freq_dict[row[\"frequency\"]]\n",
    "    file = f'{dl.dst_folder}/{row[\"filenames\"]}'\n",
    "    logger.debug(f'loading for {name}: {file}')\n",
    "    alldata[name] = pd.read_csv(file, index_col=col, parse_dates=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Summary for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.431479Z",
     "start_time": "2020-10-14T09:14:22.312Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "# Displaying all files information\n",
    "for file in alldata.keys():\n",
    "    if file in dl.manifest_df[\"name\"].to_list():\n",
    "        logger.debug(f'Information for <<{dl.manifest_df.loc[dl.manifest_df[\"name\"]==file, \"zip_file\"].sum()}>> tag({file})')\n",
    "        logger.debug(f'Category=>    {dl.manifest_df.loc[dl.manifest_df[\"name\"]==file, \"category\"].sum()}')\n",
    "        logger.debug(f'Description=> {dl.manifest_df.loc[dl.manifest_df[\"name\"]==file, \"description\"].sum()}')\n",
    "        logger.debug(f'Data shape=>  {alldata[file].shape}')\n",
    "        freq = dl.manifest_df.loc[dl.manifest_df[\"name\"]==file, \"frequency\"].sum()\n",
    "        uniq = alldata[file].index.unique()\n",
    "        logger.debug(f'Data\\'s year range from [min]:[{uniq.min().year}] to [max]:[{uniq.max().year}]')\n",
    "        logger.debug(f\"\\n{alldata[file].head()}\")\n",
    "        logger.debug('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.431479Z",
     "start_time": "2020-10-14T09:14:22.314Z"
    }
   },
   "outputs": [],
   "source": [
    "# load cpi data into a dataframe\n",
    "alldata['cpi'] = pd.read_csv(data_files['cpi'], index_col='month', parse_dates=['month'])\n",
    "# load fuel data into a dataframe\n",
    "alldata['fuel'] = pd.read_csv(data_files['fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unable to use/map the following files\n",
    "Unable to use a large amount of the files as shown in the table below. \n",
    "\n",
    "|    tag      |  Description                                         |  Reason               |\n",
    "|:------------|:-----------------------------------------------------|:----------------------|\n",
    "| reg_make_yr | Annual New Registration of Cars by Make              | breakdown by make     |\n",
    "| reg_type_yr | Annual New Registration of Cars by Make              | breakdown by make, fuel, type |\n",
    "| reg_bus_make| Annual New Registration of Buses by Make             | breakdown by make     |\n",
    "| reg_GV_make | Annual New Registration of Goods Vehicles by Make    | breakdown by make     |\n",
    "| reg_GV_type | Annual New Registration of Goods Vehicles by Make    | breakdown by make, fuel, type |\n",
    "| reg_MC_make | Annual New Registration of Motorcycles by Make       | breakdown by make     |\n",
    "| reg_make_mth| Monthly New Registration of Cars by Make             | breakdown by make, fuel, type |\n",
    "| reg_gvbus_make_mth| Monthly New Registration of Goods Vehicles & Buses by Make | breakdown by make, fuel, type |\n",
    "| reg_mc_make_mth| Monthly New Registration of Motorcycles by Make   | breakdown by make     |\n",
    "| reg_opc_new_mth| Monthly New Registration of Off Peak Cars (Including Population of OPCWEC) | no category  |\n",
    "| reg_opc_total_mth| Monthly total Off Peak Cars (Including Population of OPCWEC) | no category  |\n",
    "| age_dist_bus| Annual Age Distribution of Buses                                  | no category  |\n",
    "| age_dist_mc| Annual Age Distribution of Motorcycles                             | no category  |\n",
    "| pop_bus_cap| Annual Bus Population By Passenger Capacity                        | not relevant to this project |\n",
    "| pop_car_make| Annual Car Population by Make                        | breakdown by make     | \n",
    "| pop_bus_make| Annual Bus Population By Make                        | breakdown by make     |\n",
    "| pop_gv_make| Annual Goods Vehicle Population By Make               | breakdown by make     |\n",
    "| pop_gv_weight| Annual Goods Vehicle Population by Type and Maximum Laden Weight | breakdown by laden weight and type |\n",
    "| mile_car   | Annual Mileage for Private Motor Vehicle              | not relevant to this project |\n",
    "| pass_car   | Passing Rate of Motor Vehicles on First Inspection    | not relevant to this project |\n",
    "| pop_car_fuel| Annual Motor Vehicle Population by Type of Fuel Used | breakdown by type and engine |\n",
    "| pop_car_type| Annual Motor Vehicle Population by Vehicle Type      | breakdown by vehicle category and type |\n",
    "| pop_mc_cc  | Annual Motorcycle Population by CC Rating             | breakdown by CC |\n",
    "| pop_mc_make| Annual Motorcycle Population by Make                  | breakdown by make     |\n",
    "| pop_car_fuel_mth| Monthly Motor Vehicle Population Statistics by Type of Fuel Used | breakdown by vehicle category and type |\n",
    "| pop_dereg_qtr| Quarterly De-Registration and Population of Motor Vehicle | breakdown by vehicle category and type |\n",
    "| pop_reg_qtr| Quarterly Registration and Population of Motor Vehicle      | breakdown by vehicle category and type |\n",
    "| trans_car_make| Annual Effective Transfer of Car Ownership by Make       | breakdown by make |\n",
    "| trans_car_type| Annual Type and Number of Motor Vehicles Transferred     | breakdown by type |\n",
    "| trans_car_make_mth| Monthly Effective Transfer of Car Ownership by Make  | breakdown by make |\n",
    "| trans_car_type_mth| Monthly Type and Number of Vehicles Transferred      | breakdown by type |\n",
    "| reval_coe  | Annual Revalidation of COE of Existing Vehicles             | breakdown by type |\n",
    "| coe_pqp    | COE Bidding Results for PQP                                 | PQP is derived from COE premium |\n",
    "\n",
    "\n",
    "After analysis of the files downloaded from LTA, due to the date range available and relevance as shown above. <br> The list of files have been shortlisted into this list below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.432477Z",
     "start_time": "2020-10-14T09:14:22.317Z"
    }
   },
   "outputs": [],
   "source": [
    "# shortlist of files that we are using\n",
    "files = ['dereg_quota', 'reg_quota', 'coe_results', 'dereg_vqs', \n",
    "         'reg_quota_mth', 'reval_coe_mth', 'age_dist_car', 'age_dist_gv', \n",
    "         'pop_car_cc', 'pop_car_quota', 'age_dist_mc_mth', 'pop_car_quota_mth', \n",
    "         'pop_car_type_mth', 'cpi', 'fuel']\n",
    "print(f'Number of files shortlisted is {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.432477Z",
     "start_time": "2020-10-14T09:14:22.319Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "# checking of datatypes\n",
    "for file in files:\n",
    "    logger.debug('------------------------------------------------------------------------')\n",
    "    logger.debug(f'Checking datatypes for {file}')\n",
    "    logger.debug(f'------------------------------------------------------------------------\\\n",
    "                    \\n{alldata[file].dtypes}')\n",
    "    logger.debug('------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are correct with the exception of \"**change**\" column in \"**fuel**\" file. Will look further into this in the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.433474Z",
     "start_time": "2020-10-14T09:14:22.322Z"
    }
   },
   "outputs": [],
   "source": [
    "# variables cleanup after file summary\n",
    "del col, file, freq, i, row, name, uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T11:57:08.541262Z",
     "start_time": "2020-10-05T11:57:08.534250Z"
    }
   },
   "source": [
    "---\n",
    "## Data Processing\n",
    "In this section we will be looking in-depth into each of the shortlisted files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### COE results file\n",
    "This is the file holding the main source of data for this project and is downloaded from LTA. <br>\n",
    "As we are focusing on only Category A, B and D, we will filtering out the other 2 categories D and E. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.434471Z",
     "start_time": "2020-10-14T09:14:22.326Z"
    }
   },
   "outputs": [],
   "source": [
    "# The main dataframe for this project, coe_df\n",
    "# Creating a copy of COE results DataFrame for analysis\n",
    "coe_df = alldata['coe_results'].copy()\n",
    "# Filtering out bidding no 1 from analysis\n",
    "coe_df = coe_df[coe_df['bidding_no']==2]\n",
    "coe_df.drop(['bidding_no'], axis=1, inplace=True)\n",
    "# Removing the motocycle category\n",
    "coe_df = coe_df[coe_df['vehicle_class']!='Category D']\n",
    "# Removing the open category\n",
    "coe_df = coe_df[coe_df['vehicle_class']!='Category E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.434471Z",
     "start_time": "2020-10-14T09:14:22.328Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coe_df['period'] = coe_df.index.to_period('M')\n",
    "coe_df['year'] = coe_df.index.year\n",
    "coe_df['month'] = coe_df.index.month\n",
    "coe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.435469Z",
     "start_time": "2020-10-14T09:14:22.330Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running a standard check on the coe_df\n",
    "util.df_checker('coe_df', coe_df, 'vehicle_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check on the coe_df has flagged out 3 missing values in the index. These are months Apr to Jun 2020, upon checking it was found that COE bidding was halted during the circuit breaker thus these dates were missing. Will be looking into these missing months in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CPI (Consumer Price Index) file\n",
    "To supplement the information from LTA, we have downloaded Singapore's CPI from Department of Statistics Singapore [here](https://www.tablebuilder.singstat.gov.sg/publicfacing/createDataTable.action?refId=16854). <br>\n",
    "For this file we are focusing on the CPI for 'All Items', hence we have filtered level_1 to 'All Items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.436466Z",
     "start_time": "2020-10-14T09:14:22.333Z"
    }
   },
   "outputs": [],
   "source": [
    "# check cpi information\n",
    "cpi_df = alldata['cpi']\n",
    "cpi_df.columns = cpi_df.columns.str.lower()\n",
    "cpi_df['period'] = cpi_df.index.to_period('M')\n",
    "# select only All Items for analysis\n",
    "cpi_df = cpi_df[cpi_df['level_1']=='All Items'].copy()\n",
    "cpi_df.rename(columns={'value':'cpi'}, inplace=True)\n",
    "cpi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.436466Z",
     "start_time": "2020-10-14T09:14:22.337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform usual checks on dataframe\n",
    "util.df_checker('cpi_df', cpi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good from the checks. Next we are creating a dictionary to hold the information to merge cpi_df into coe_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.437463Z",
     "start_time": "2020-10-14T09:14:22.339Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of dataframe and cols to be merged into coe_df\n",
    "merge_cols = [{'name':'cpi',\n",
    "               'df': cpi_df, \n",
    "               'cols': ['cpi','period']\n",
    "              }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fuel price  file\n",
    "Another file downloaded to supplement the information from LTA, is the Fuel price information.<br> This file is downloaded from indexmundi.com [here](https://www.indexmundi.com/commodities/?commodity=gasoline&months=360&currency=sgd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.438461Z",
     "start_time": "2020-10-14T09:14:22.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# check fuel information\n",
    "fuel_df = alldata['fuel']\n",
    "fuel_df.columns = fuel_df.columns.str.lower()\n",
    "# convert month to datetime datatype\n",
    "fuel_df['month'] = fuel_df['month'].map(lambda x: dt.datetime.strptime(x, '%b-%y'))\n",
    "fuel_df.set_index('month', inplace=True)\n",
    "# create period column for merging with coe_df\n",
    "fuel_df['period'] = fuel_df.index.to_period('M')\n",
    "fuel_df.rename(columns={'price':'fuel_price'}, inplace=True)\n",
    "fuel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.438461Z",
     "start_time": "2020-10-14T09:14:22.345Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform usual checks on dataframe\n",
    "util.df_checker('fuel_df', fuel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checks didn't turn out any issues. Next we are creating a dictionary to hold the information to merge fuel_df into coe_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.439458Z",
     "start_time": "2020-10-14T09:14:22.347Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of dataframe and cols to be merged into coe_df\n",
    "merge_cols.append({\n",
    "    'name':'fuel',\n",
    "    'df': fuel_df,\n",
    "    'cols': ['fuel_price','period']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### New registration quota\n",
    "This section will cover the 2 new registration quota files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New register car quota (year) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.440455Z",
     "start_time": "2020-10-14T09:14:22.351Z"
    }
   },
   "outputs": [],
   "source": [
    "# check new register car quota year\n",
    "reg_yr_df = alldata['reg_quota']\n",
    "reg_yr_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New register car quota (month) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.440455Z",
     "start_time": "2020-10-14T09:14:22.354Z"
    }
   },
   "outputs": [],
   "source": [
    "# check new register car quota month\n",
    "reg_mth_df = alldata['reg_quota_mth']\n",
    "reg_mth_df['period'] = reg_mth_df.index.to_period('M')\n",
    "reg_mth_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing the monthly data from annual data\n",
    "As new register car quota monthly data only available from 2014, will impute the monthly data for 2010 t0 2013 from the annual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.441452Z",
     "start_time": "2020-10-14T09:14:22.357Z"
    }
   },
   "outputs": [],
   "source": [
    "# start and end date of missing data\n",
    "start_date = dt.datetime(2010, 1, 1)\n",
    "end_date = dt.datetime(2013, 12, 31)\n",
    "\n",
    "# list of months from 2010 till 2013\n",
    "mths = [ mth.strftime('%Y-%m') for mth in rrule(freq=MONTHLY, dtstart=start_date, until=end_date) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.442450Z",
     "start_time": "2020-10-14T09:14:22.359Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop to populate the monthly data for 2010 till 2013\n",
    "for mth in mths:\n",
    "    yr = int(mth[0:4])\n",
    "    for cat in list(reg_mth_df['category'].unique()):\n",
    "        idx = dt.datetime.strptime(mth, '%Y-%m')\n",
    "        num = reg_yr_df.loc[(reg_yr_df.index.year==yr) & \n",
    "                            (reg_yr_df['category']==cat)]['number'].sum()//12\n",
    "        if num > 0:\n",
    "            reg_mth_df = reg_mth_df.append(pd.DataFrame({'category': cat, \n",
    "                                                  'number': num}, index=[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.442450Z",
     "start_time": "2020-10-14T09:14:22.361Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_mth_df['period'] = reg_mth_df.index.to_period('M')\n",
    "reg_mth_df.sort_index(inplace=True)\n",
    "reg_mth_df.rename(columns={'number':'reg'}, inplace=True)\n",
    "# confirm if the missing years have been added\n",
    "reg_mth_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.443446Z",
     "start_time": "2020-10-14T09:14:22.363Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparing the data across year and month dataframe\n",
    "yr = 2010\n",
    "display(reg_yr_df[reg_yr_df.index.year==yr])\n",
    "display(reg_mth_df[reg_mth_df.index.year==yr].groupby('category').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.444445Z",
     "start_time": "2020-10-14T09:14:22.365Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform usual checks on dataframe\n",
    "util.df_checker('reg_mth_df', reg_mth_df, 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good from the checks. Next we are creating a dictionary to hold the information to merge reg_df into coe_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.444445Z",
     "start_time": "2020-10-14T09:14:22.367Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of dataframe and cols to be merged into coe_df\n",
    "merge_cols.append({\n",
    "    'name':'reg',\n",
    "    'df': reg_mth_df,\n",
    "    'cols': ['reg','period']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Deregistration quota\n",
    "This section will cover the 2 deregistration quota files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deregister car quota (year) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.445441Z",
     "start_time": "2020-10-14T09:14:22.370Z"
    }
   },
   "outputs": [],
   "source": [
    "# check deregister car quota\n",
    "dereg_yr_df = alldata['dereg_quota']\n",
    "dereg_yr_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deregister car quota (month) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.446439Z",
     "start_time": "2020-10-14T09:14:22.373Z"
    }
   },
   "outputs": [],
   "source": [
    "# check deregister car quota\n",
    "dereg_mth_df = alldata['dereg_vqs']\n",
    "dereg_mth_df['period'] = dereg_mth_df.index.to_period('M')\n",
    "dereg_mth_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing the monthly data from annual data\n",
    "As deregister car quota monthly data only available from 2014, will impute the monthly data for 2010 t0 2013 from the annual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.446439Z",
     "start_time": "2020-10-14T09:14:22.375Z"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda x : x if x!= 'Vehicles Exempted from VQS' else 'Vehicles Exempted From VQS'\n",
    "dereg_mth_df['category'] = dereg_mth_df['category'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.447436Z",
     "start_time": "2020-10-14T09:14:22.377Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop to populate the monthly data for 2010 till 2013\n",
    "for mth in mths:\n",
    "    yr = int(mth[0:4])\n",
    "    for cat in list(dereg_mth_df['category'].unique()):\n",
    "        idx = dt.datetime.strptime(mth, '%Y-%m')\n",
    "        num = dereg_yr_df.loc[(dereg_yr_df.index.year==yr) & \n",
    "                            (dereg_yr_df['category']==cat)]['number'].sum()//12\n",
    "        if num > 0:\n",
    "            dereg_mth_df = dereg_mth_df.append(pd.DataFrame({'category': cat, \n",
    "                                                  'number': num}, index=[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.448434Z",
     "start_time": "2020-10-14T09:14:22.379Z"
    }
   },
   "outputs": [],
   "source": [
    "dereg_mth_df['period'] = dereg_mth_df.index.to_period('M')\n",
    "dereg_mth_df.sort_index(inplace=True)\n",
    "dereg_mth_df.rename(columns={'number':'dereg'}, inplace=True)\n",
    "# confirm if the missing years have been added\n",
    "dereg_mth_df.index.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.448434Z",
     "start_time": "2020-10-14T09:14:22.380Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Comparing the data across year and month dataframe\n",
    "yr = 2010\n",
    "display(dereg_yr_df[dereg_yr_df.index.year==yr])\n",
    "display(dereg_mth_df[dereg_mth_df.index.year==yr].groupby('category').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.449430Z",
     "start_time": "2020-10-14T09:14:22.382Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform usual checks on dataframe\n",
    "util.df_checker('dereg_mth_df', dereg_mth_df, 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good from the checks. Next we are creating a dictionary to hold the information to merge dereg_df into coe_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.450428Z",
     "start_time": "2020-10-14T09:14:22.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of dataframe and cols to be merged into coe_df\n",
    "merge_cols.append({\n",
    "    'name':'dereg',\n",
    "    'df': dereg_mth_df,\n",
    "    'cols': ['dereg','period']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data consolidation and features creation\n",
    "In this section, the all the dataframes will be merged into one single dataframe for further analysis and modelling. <br> Lag and rolling average features will be created as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.450428Z",
     "start_time": "2020-10-14T09:14:22.388Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary to hold the merged dataframes\n",
    "coe_list = dict()\n",
    "cats = list(coe_df['vehicle_class'].unique())\n",
    "\n",
    "# looping through each category to create a \n",
    "for cat in cats:\n",
    "    coe_list[cat] = coe_df[coe_df['vehicle_class']==cat]\n",
    "    for d in merge_cols:\n",
    "        logger.debug(f\"cat:{cat} name:{d['name']} cols{d['cols']}\")\n",
    "        if d['name']=='cpi' or d['name']=='fuel':\n",
    "            coe_list[cat] = pd.merge(coe_list[cat], d['df'][d['cols']], on='period')\n",
    "        else:\n",
    "            t_df = d['df'][d['df']['category']==cat]\n",
    "            coe_list[cat] = pd.merge(coe_list[cat], t_df[d['cols']], on='period')\n",
    "    coe_list[cat].index = coe_list[cat]['period'].map(lambda x : pd.to_datetime(f'{x.year}-{x.month:02d}'))\n",
    "    coe_list[cat]['period'] = coe_list[cat]['period'].map(lambda x : f'{x.year}-{x.month:02d}')\n",
    "    coe_list[cat]['cpi'] = coe_list[cat]['cpi'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.451426Z",
     "start_time": "2020-10-14T09:14:22.390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the shift/lag features\n",
    "new_feats = ['cpi', 'fuel_price', 'dereg', 'premium']\n",
    "shift = [1,2,3,5,10,15,20,24,48]\n",
    "\n",
    "for cat in cats:\n",
    "    lag_df = pd.DataFrame()\n",
    "    tmp_df = coe_list[cat]\n",
    "    for feat in new_feats:\n",
    "        for sh in shift:\n",
    "            logger.debug(f'{cat} shape for {feat}{sh} is {tmp_df.shape}')\n",
    "            tmp_df[f'{feat}_s{sh}'] = tmp_df[feat].shift(sh)\n",
    "            tmp_df[f'{feat}_s{sh}'].fillna(tmp_df[feat], inplace=True)\n",
    "    lag_df = pd.concat([lag_df, tmp_df])\n",
    "    coe_list[cat] = lag_df\n",
    "    coe_list[cat]['diff1'] = coe_list[cat]['premium'].diff()\n",
    "    # creating exponentially weighted moving average (ewma)\n",
    "    coe_list[cat]['bids_success_ema3'] = pd.Series.ewm(coe_list[cat]['bids_success'], span=3).mean()\n",
    "    coe_list[cat]['bids_received_ema3'] = pd.Series.ewm(coe_list[cat]['bids_received'], span=3).mean()\n",
    "    coe_list[cat]['quota_ema3'] = pd.Series.ewm(coe_list[cat]['quota'], span=3).mean()\n",
    "    coe_list[cat]['actuals'] = coe_list[cat]['premium']\n",
    "    coe_list[cat]['baseline'] = coe_list[cat]['premium'].rolling(6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.451426Z",
     "start_time": "2020-10-14T09:14:22.392Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coe_list['Category C'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.452424Z",
     "start_time": "2020-10-14T09:14:22.395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting log level to ERROR to filter out standard library logs\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.453421Z",
     "start_time": "2020-10-14T09:14:22.397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting COE against Quota\n",
    "util.plot_target('Plot for COE vs Quota', coe_list, 'quota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.454429Z",
     "start_time": "2020-10-14T09:14:22.399Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting COE against CPI\n",
    "util.plot_target('Plot for COE vs CPI', coe_list, 'cpi', 'cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.455416Z",
     "start_time": "2020-10-14T09:14:22.400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting COE against Fuel Price\n",
    "util.plot_target('Plot for COE vs Fuel Price', coe_list, 'fuel_price', 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.455416Z",
     "start_time": "2020-10-14T09:14:22.402Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.456412Z",
     "start_time": "2020-10-14T09:14:22.404Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [ i for i in coe_list['Category A'].columns if not i.startswith('premium') ]\n",
    "cols.remove('actuals')\n",
    "cols.remove('vehicle_class')\n",
    "cols.remove('period')\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.457409Z",
     "start_time": "2020-10-14T09:14:22.405Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = len(cols)\n",
    "util.plot_scatter(coe_list['Category A'], 3, [ [c,'premium'] for c in cols ], cols, cols, ['premium']*p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.457409Z",
     "start_time": "2020-10-14T09:14:22.407Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "util.plot_hist(coe_list['Category A'], 3, cols, cols, cols, ['premium']*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.458406Z",
     "start_time": "2020-10-14T09:14:22.410Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "catA = 'Category A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.459405Z",
     "start_time": "2020-10-14T09:14:22.412Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats = ['premium', 'cpi_s1', 'cpi_s2', 'cpi_s3', 'cpi_s5', 'cpi_s10', 'cpi_s15', 'cpi_s20', 'cpi_s24', 'cpi_s48',]\n",
    "sns.heatmap(coe_list[catA][feats].corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.459405Z",
     "start_time": "2020-10-14T09:14:22.414Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = ['premium', 'fuel_price_s1', 'fuel_price_s2', 'fuel_price_s3', 'fuel_price_s5', \n",
    "         'fuel_price_s10', 'fuel_price_s15', 'fuel_price_s20', 'fuel_price_s24', 'fuel_price_s48',]\n",
    "sns.heatmap(coe_list[catA][feats].corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.460401Z",
     "start_time": "2020-10-14T09:14:22.415Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = ['premium', 'quota_ema3', 'bids_success_ema3', 'bids_received_ema3',\n",
    "         'premium_s1', 'premium_s2', 'premium_s3', 'premium_s5',]\n",
    "sns.heatmap(coe_list[catA][feats].corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.460401Z",
     "start_time": "2020-10-14T09:14:22.418Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis of the target to check for autocorrection\n",
    "catA = coe_list['Category A']\n",
    "util.time_plots(catA, 'premium', 24, 'multiplicative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.461399Z",
     "start_time": "2020-10-14T09:14:22.420Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis of the diff1 on target to check for autocorrection\n",
    "util.time_plots(catA, 'diff1', 24, 'additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.462397Z",
     "start_time": "2020-10-14T09:14:22.421Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the data into Train and Test\n",
    "trn_df = catA[catA['period']<'2019-01'].copy()\n",
    "tst_df = catA[catA['period']>='2019-01'].copy()\n",
    "\n",
    "print(f'train dataset shape: {trn_df.shape}')\n",
    "print(f'test dataset shape: {tst_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.462397Z",
     "start_time": "2020-10-14T09:14:22.423Z"
    }
   },
   "outputs": [],
   "source": [
    "GRIDSEARCH=False\n",
    "# GridSearch ARIMA for best p and q (~5mins)\n",
    "if GRIDSEARCH:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    util.gs_arima(trn_df, tst_df)\n",
    "    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GridSearch above the optimal order is (0,0,2) <br>\n",
    "However for our ARIMA prediction, we will be changing p to 1 after reviewing the acf and pacf charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.463394Z",
     "start_time": "2020-10-14T09:14:22.426Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prediction with ARIMA\n",
    "util.arima(trn_df, tst_df, (1,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T08:15:31.596497Z",
     "start_time": "2020-10-06T08:15:31.592508Z"
    }
   },
   "source": [
    "---\n",
    "## Modelling\n",
    "In this section we will be using Linear regression and XGBoost regressor models to COE premium "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.464392Z",
     "start_time": "2020-10-14T09:14:22.429Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create instance of DeployModel\n",
    "dpm = dm.DeployModel();\n",
    "dpm.set_df(coe_list)\n",
    "dpm.set_shift(new_feats, shift)\n",
    "dpm.set_target('premium')\n",
    "dpm.insert_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.464392Z",
     "start_time": "2020-10-14T09:14:22.430Z"
    }
   },
   "outputs": [],
   "source": [
    "# features for linear regression\n",
    "lr_feats = ['cpi_s1', 'cpi_s2', 'cpi_s3', \n",
    "            'fuel_price_s1', 'fuel_price_s2', 'fuel_price_s3',\n",
    "            'cpi_s5', 'cpi_s10', 'cpi_s15', 'cpi_s20', 'cpi_s24', 'cpi_s48',\n",
    "            'fuel_price_s5', 'fuel_price_s10', 'fuel_price_s15', 'fuel_price_s20',\n",
    "            'fuel_price_s24', 'fuel_price_s48', \n",
    "            'quota_ema3', 'bids_success_ema3', 'bids_received_ema3',\n",
    "            'premium_s1', 'premium_s2', 'premium_s3', 'premium_s5',\n",
    "           ]\n",
    "len(lr_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.465389Z",
     "start_time": "2020-10-14T09:14:22.432Z"
    }
   },
   "outputs": [],
   "source": [
    "dpm.set_feats('lr', lr_feats)\n",
    "dpm.train_test_split('lr', '2019-01')\n",
    "dpm.set_model('lr', LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.465389Z",
     "start_time": "2020-10-14T09:14:22.433Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression for Category A\n",
    "lrA = dpm.modelling('lr','Category A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.466386Z",
     "start_time": "2020-10-14T09:14:22.435Z"
    }
   },
   "outputs": [],
   "source": [
    "# metrics for Category A Linear Regression\n",
    "results = lrA['results']\n",
    "metrics = lrA['metrics']\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.467382Z",
     "start_time": "2020-10-14T09:14:22.437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Linear Regression for Category B\n",
    "lrB = dpm.modelling('lr','Category B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.467382Z",
     "start_time": "2020-10-14T09:14:22.439Z"
    }
   },
   "outputs": [],
   "source": [
    "# metrics for Category B Linear Regression\n",
    "results.update(lrB['results'])\n",
    "metrics.update(lrB['metrics'])\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.468380Z",
     "start_time": "2020-10-14T09:14:22.440Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression for Category C\n",
    "lrC = dpm.modelling('lr','Category C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.469378Z",
     "start_time": "2020-10-14T09:14:22.442Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics for Category C Linear Regression\n",
    "results.update(lrC['results'])\n",
    "metrics.update(lrC['metrics'])\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.470379Z",
     "start_time": "2020-10-14T09:14:22.445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features for Category A XGBoost regressor\n",
    "xgb_feats = ['cpi_s1', 'cpi_s2', 'cpi_s3', 'fuel_price_s1', 'fuel_price_s2', \n",
    "             'fuel_price_s3', 'cpi_s5', 'cpi_s10', 'cpi_s15', 'cpi_s20', 'cpi_s24', \n",
    "             'cpi_s48', 'fuel_price_s5', 'fuel_price_s10', 'fuel_price_s15', \n",
    "             'fuel_price_s20', 'fuel_price_s24', 'fuel_price_s48', 'year',\n",
    "             'quota_ema3', 'bids_success_ema3', 'bids_received_ema3',\n",
    "             'dereg_s1', 'dereg_s2',\n",
    "            ]\n",
    "dpm.set_feats('xgbA', xgb_feats)\n",
    "logger.info(f'Category A: number of features {len(xgb_feats)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.471372Z",
     "start_time": "2020-10-14T09:14:22.447Z"
    }
   },
   "outputs": [],
   "source": [
    "# features for Category B XGBoost regressor\n",
    "xgb_feats = ['cpi_s1', 'cpi_s2', 'cpi_s3', 'fuel_price_s1', 'fuel_price_s2', \n",
    "             'fuel_price_s3', 'cpi_s5', 'cpi_s10', 'cpi_s15', 'cpi_s20', 'cpi_s24', \n",
    "             'cpi_s48', 'fuel_price_s5', 'fuel_price_s10', 'fuel_price_s15', \n",
    "             'fuel_price_s20', 'fuel_price_s24', 'fuel_price_s48', 'year',\n",
    "             'quota_ema3', 'bids_success_ema3', 'bids_received_ema3', 'dereg_s1', \n",
    "             'premium_s1', 'premium_s2', 'premium_s3', 'premium_s5',\n",
    "            ]\n",
    "dpm.set_feats('xgbB', xgb_feats)\n",
    "logger.info(f'Category B: number of features {len(xgb_feats)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.471372Z",
     "start_time": "2020-10-14T09:14:22.449Z"
    }
   },
   "outputs": [],
   "source": [
    "# features for Category C XGBoost regressor\n",
    "xgb_feats = ['cpi_s1', 'cpi_s2', 'cpi_s3', 'fuel_price_s1', 'fuel_price_s2', \n",
    "             'fuel_price_s3', 'cpi_s5', 'cpi_s10', 'cpi_s15', 'cpi_s20', 'cpi_s24', \n",
    "             'cpi_s48', 'fuel_price_s5', 'fuel_price_s10', 'fuel_price_s15', \n",
    "             'fuel_price_s20', 'fuel_price_s24', 'fuel_price_s48', 'year', 'month',\n",
    "             'quota_ema3', 'bids_success_ema3', 'bids_received_ema3',\n",
    "             'premium_s1', 'premium_s2', 'premium_s3', 'premium_s5',\n",
    "            ]\n",
    "dpm.set_feats('xgbC', xgb_feats)\n",
    "logger.info(f'Category C: number of features {len(xgb_feats)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.472370Z",
     "start_time": "2020-10-14T09:14:22.450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split the xgb set of data\n",
    "dpm.train_test_split('xgb', '2019-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best XGBoost regressor hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.473369Z",
     "start_time": "2020-10-14T09:14:22.453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline model XGBoost Regressor for GridSearch\n",
    "xgb_pipe = Pipeline([\n",
    "        ('xgb', XGBRegressor(random_state=42, \n",
    "                              objective='reg:squarederror', \n",
    "                              verbosity=1, n_jobs=-1))\n",
    "    ])\n",
    "# XGBoost Regressor Parameters for GridSearch\n",
    "xgb_params = {  'xgb__learning_rate': [0.05, 0.1],\n",
    "                'xgb__max_depth': [3, 4, 5],\n",
    "                'xgb__min_child_weight': [4, 5, 6],\n",
    "                'xgb__gamma': [0.7, 0.8],\n",
    "                'xgb__subsample': [ 0.8, 0.9],\n",
    "                'xgb__n_estimators': [300, 400, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.473369Z",
     "start_time": "2020-10-14T09:14:22.454Z"
    }
   },
   "outputs": [],
   "source": [
    "GRIDSEARCH=False\n",
    "# GridSearch to find the best hyperparameter (~45mins)\n",
    "if GRIDSEARCH:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    for cat in coe_list.keys():\n",
    "        gs = GridSearchCV(xgb_pipe, param_grid=xgb_params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        gs.fit(dpm.split_df['xgb'][cat]['X_trn_sc'], dpm.split_df['xgb'][cat]['y_train'])\n",
    "        logger.debug(f\"XGBoost for {cat} best_params:\\n{gs.best_params_}\")\n",
    "    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After GridSearch, next we will start to create instances of XGBoost Regressors with the best parameters for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.474365Z",
     "start_time": "2020-10-14T09:14:22.457Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBRegressor is fitted with GridSearch parameters\n",
    "dpm.set_model('xgbA', XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    gamma=0.7,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    min_child_weight=6,\n",
    "    n_estimators=400,\n",
    "    subsample=0.8\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.474365Z",
     "start_time": "2020-10-14T09:14:22.458Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBoost Regressor for Category A\n",
    "xgbA = dpm.modelling('xgb','Category A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.475362Z",
     "start_time": "2020-10-14T09:14:22.460Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics for Category A XGBoost Regressor\n",
    "results.update(xgbA['results'])\n",
    "metrics.update(xgbA['metrics'])\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.476359Z",
     "start_time": "2020-10-14T09:14:22.462Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBRegressor is fitted with GridSearch parameters\n",
    "dpm.set_model('xgbB', XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    gamma=0.7,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_child_weight=4,\n",
    "    n_estimators=500,\n",
    "    subsample=0.7\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.476359Z",
     "start_time": "2020-10-14T09:14:22.463Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBoost Regressor for Category B\n",
    "xgbB = dpm.modelling('xgb','Category B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.477356Z",
     "start_time": "2020-10-14T09:14:22.465Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# metrics for Category B XGBoost Regressor\n",
    "results.update(xgbB['results'])\n",
    "metrics.update(xgbB['metrics'])\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.477356Z",
     "start_time": "2020-10-14T09:14:22.467Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBRegressor is fitted with GridSearch parameters\n",
    "dpm.set_model('xgbC', XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    gamma=0.7,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_child_weight=6,\n",
    "    n_estimators=400,\n",
    "    subsample=0.7\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.478354Z",
     "start_time": "2020-10-14T09:14:22.469Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBoost Regressor for Category C\n",
    "xgbC = dpm.modelling('xgb','Category C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.479350Z",
     "start_time": "2020-10-14T09:14:22.471Z"
    }
   },
   "outputs": [],
   "source": [
    "# metrics for Category C XGBoost Regressor\n",
    "results.update(xgbC['results'])\n",
    "metrics.update(xgbC['metrics'])\n",
    "display(pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.480364Z",
     "start_time": "2020-10-14T09:14:22.473Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpm.interpret_xgb('xgb', 'Category C', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.480364Z",
     "start_time": "2020-10-14T09:14:22.475Z"
    }
   },
   "outputs": [],
   "source": [
    "dpm.gen_feat_map('xgb', 'Category A', data_files['feat_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.481345Z",
     "start_time": "2020-10-14T09:14:22.476Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpm.plot_tree('xgb', 'Category A', data_files['feat_map'], 300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.482343Z",
     "start_time": "2020-10-14T09:14:22.480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle model for deployment\n",
    "pickle.dump(dpm, open(data_files['pickle'], 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting forward\n",
    "In this section we will be looking at the models' performance when predicting at different window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.482343Z",
     "start_time": "2020-10-14T09:14:22.482Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.483341Z",
     "start_time": "2020-10-14T09:14:22.484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup parameters for this analysis\n",
    "n_pred = 12\n",
    "cat = 'Category C'\n",
    "cut_off = '2019-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with window of 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.484338Z",
     "start_time": "2020-10-14T09:14:22.487Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparation of predicting with windown of 6\n",
    "win_size = 6\n",
    "dpm.crop_df(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.484338Z",
     "start_time": "2020-10-14T09:14:22.489Z"
    }
   },
   "outputs": [],
   "source": [
    "win6 = pd.DataFrame()\n",
    "for i in range(int(n_pred/win_size)):\n",
    "    dpm.append_dates(dpm.df[cat].index.max(), win_size)\n",
    "    dpm.train_test_split('xgb', cut_off)\n",
    "    tmp6 = dpm.modelling('xgb', cat, plot=False)\n",
    "    win6 = pd.DataFrame(tmp6['results'][f'xgb{cat[-1]}'])\n",
    "    dpm.update_actual(win_size)\n",
    "#win6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.485335Z",
     "start_time": "2020-10-14T09:14:22.491Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse6 = round(dpm.rmse(win6['actual'], win6['pred']),2)\n",
    "print(f'RMSE score for window size 6: {rmse6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with window of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.486333Z",
     "start_time": "2020-10-14T09:14:22.493Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparation of predicting with windown of 3\n",
    "win_size = 3\n",
    "dpm.crop_df(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.487330Z",
     "start_time": "2020-10-14T09:14:22.495Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "win3 = pd.DataFrame()\n",
    "for i in range(int(n_pred/win_size)):\n",
    "    dpm.append_dates(dpm.df[cat].index.max(), win_size)\n",
    "    dpm.train_test_split('xgb', cut_off)\n",
    "    tmp3 = dpm.modelling('xgb', cat, plot=False)\n",
    "    win3 = pd.DataFrame(tmp3['results'][f'xgb{cat[-1]}'])\n",
    "    dpm.update_actual(win_size)\n",
    "#win3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.488327Z",
     "start_time": "2020-10-14T09:14:22.497Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse3 = round(dpm.rmse(win3['actual'], win3['pred']),2)\n",
    "print(f'RMSE score for window size 6: {rmse6}')\n",
    "print(f'RMSE score for window size 3: {rmse3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with window of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.489324Z",
     "start_time": "2020-10-14T09:14:22.500Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparation of predicting with windown of 1\n",
    "win_size = 1\n",
    "dpm.crop_df(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.489324Z",
     "start_time": "2020-10-14T09:14:22.502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "win1 = pd.DataFrame()\n",
    "for i in range(int(n_pred/win_size)):\n",
    "    dpm.append_dates(dpm.df[cat].index.max(), win_size)\n",
    "    dpm.train_test_split('xgb', cut_off)\n",
    "    tmp1 = dpm.modelling('xgb', cat, plot=False)\n",
    "    win1 = pd.DataFrame(tmp1['results'][f'xgb{cat[-1]}'])\n",
    "    dpm.update_actual(win_size)\n",
    "#win1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T09:14:23.490321Z",
     "start_time": "2020-10-14T09:14:22.504Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse1 = round(dpm.rmse(win1['actual'], win1['pred']),2)\n",
    "print(f'RMSE score for window size 6: {rmse6}')\n",
    "print(f'RMSE score for window size 3: {rmse3}')\n",
    "print(f'RMSE score for window size 1: {rmse1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the RMSE score increase slightly as the window size increases. So depending on the application or business case, we can predict with a different window size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We began this project with 46 files and that quickly got reduced to 6 files which eventually left us with less than 10 features. \n",
    "Some challenges on working with real world data on top of the usual data cleaning are:\n",
    "- Finding data that are available within the same time frame, for example time frame of interest is between 2010 to 2020, datasets available may be from 2018 to 2020, or 2000 to 2012.\n",
    "- Finding data that are in the same granularity, for example when most datasets are in monthly, how to fit daily or weekly data together \n",
    "- Finding data that are categorized/grouped/labeled for your problem, for example COE categories vs CC vs Make vs passenger capacity. \n",
    "\n",
    "With limited features available, the first model we tried was Classic Time Series model ARIMA. Although the target, premium was not stationary we have taken premium's diff order 1 for ARIMA and GridSearched resulting with an order of (1,0,2). However ARIMA did not yield a very good predict.\n",
    "\n",
    "Since the time series models are out, next step was to look into feature engineering to increase the number of features for the other models that we are going to try. In feature engineering, there are two main groups that we created are shifted and EWMA features.\n",
    "- Shifted features, these are the features where values in the past have an impact to our target. Features that are shifted were ['cpi', 'fuel_price', 'dereg', 'premium'], and these are shifted by [1, 2, 3, 5, 10, 15, 20, 24, 48]. \n",
    "- EWMA Features, exponentially weighted moving average is a moving average where higher weights are given to the values that are nearer. Features that are EWMA are ['quota', 'bids_success', 'bids_received'] and they are applied on EWMA 3.\n",
    "\n",
    "Now that we have more features, ~45 features. We will use linear regression to analyze the features that has impact on the target. From the initial linear regression we were hitting RMSE of ~12K, after regularization and iterations of tuning. We were able to achieve RMSE for ~8K. \n",
    "\n",
    "Below is the top 3 features for each category from our Linear regression:\n",
    "![model metrics](../images/top_features.jpg)\n",
    "The top 3 features, premium_s1, quota_ema3 and bids_success_ema3 are consistent for both Category A and B. For Category C, quota_ema3 and bids_success_ema3 are on the 4th and 5th position which has significant impact on the target as well.\n",
    "\n",
    "Next we moved on to XGBoost Regressor to see if we can improve the RMSE further. While tuning the XGBoost Regressor we realised that using a single model and a single set was not helping. Hence we created models for each category along with it's own set of features. After many iterations of hyperparameters tuning and features selection for each model, we were able to achieve RMSE ~5K. \n",
    "<br>\n",
    "The final model metrics are as shown below:\n",
    "![model metrics](../images/metrics.jpg)\n",
    "\n",
    "prefix **lr** are Linear Regression model, the last character indicates the COE category<br>\n",
    "prefix **xgb** are XGBoost Regressor model, the last character indicates the COE category\n",
    "\n",
    "Although we have achieved a RMSE of < 5K, these models are far from perfect.\n",
    "In this project we have only scratch the surface of putting together a model to predict the COE premium.\n",
    "There are many more factors that affects COE prices. As with all corporate projects it is always a balance of Scope, Time and Cost. Projects have to be scoped in a way that it meets the business requirements, delivered on time and within cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitations of the models:\n",
    "- Limited data time frame, for this project the time frame we were looking at is from 2010 to 2020. While we were able to achieve a reasonable good RMSE, COEs have a lifespan of 10 years this 10 year cycle would not be picked up by the models. For that to happen, we should have data to contain at least a few cycles. This should help in the case of the ARIMA models as well.\n",
    "- Limited data, without feature engineering we had only a handful of features. It will be good to collect more data and include more features for the analysis. \n",
    "- Take events into account, for example Covid and Financial Crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some recommendations to further improve the models:\n",
    "- Get more data \n",
    "    - in terms of time frame, should get data that captures at least 3 to 4 cycles. For this case COE started in 1990 so should get the full data if possible.\n",
    "    - in terms of features, household income and unemployment rate\n",
    "- Encoding events into features\n",
    "    - MAS loan restrictions (When tighten or ease loan restrictions)\n",
    "    - LTA annouce growth rate changes (LTA increase/decrease growth)\n",
    "    - Car launches/events (Major car launches or event, where discount and incentives entices buyers)\n",
    "    - Vehicular Emissions Scheme ()\n",
    "- With more data we can also try Auto ARIMA\n",
    "- Sentiment of owning a car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "273.383px",
    "left": "1159.13px",
    "right": "20px",
    "top": "120px",
    "width": "292.867px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
